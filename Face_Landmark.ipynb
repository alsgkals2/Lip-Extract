{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03d1d414-1bed-46fc-8f74-74ebd4ee3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import dlib\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "from utils import *\n",
    "import os\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5ca1e-c6eb-4a14-8a4d-309a0b44d61c",
   "metadata": {},
   "source": [
    "## COLLECTING THE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808b3eba-2dce-42cb-805d-8c8c738d2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = \n",
    "WALK = os.walk('/media/data1/mhkim/FakeAVCeleb_PREPROCESSED/FRAMES_PNG/C/TEST/FAKE')\n",
    "\n",
    "list_path_fake = []\n",
    "for (a,b,c) in WALK:\n",
    "    for _c in c:\n",
    "        if '.png' in _c:\n",
    "            list_path_fake.append(os.path.join(a,_c))\n",
    "list_path_fake.sort()\n",
    "\n",
    "len(list_path_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bc464-d826-4f32-b431-9af6367aeb5a",
   "metadata": {},
   "source": [
    "## Start Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35cf7a40-e835-40ed-b20a-e6bbae89530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def midpoint(p1, p2):\n",
    "    coords = (p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2\n",
    "    return [int(x) for x in coords]\n",
    "\n",
    "def preprocessing(list_path_fake, find_main_point = False):\n",
    "    dict_landmark = {}\n",
    "    img_list = list_path_fake\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    for file in img_list:\n",
    "        img = cv2.imread(file) #img must be cropped into face\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        if len(rects) > 0:\n",
    "            for rect in rects:\n",
    "                if find_main_point:\n",
    "                    x = rect.left()\n",
    "                    y = rect.top()\n",
    "                    w = rect.right()\n",
    "                    h = rect.bottom()\n",
    "                    img = img[y:h, x:w]\n",
    "\n",
    "                shape = predictor(img, rect)\n",
    "                shape_np = face_utils.shape_to_np(shape).tolist()\n",
    "                if find_main_point:\n",
    "                    left_eye = midpoint(shape_np[36], shape_np[39])\n",
    "                    right_eye = midpoint(shape_np[42], shape_np[45])\n",
    "                    features = [left_eye, right_eye, shape_np[33], shape_np[48], shape_np[54]]\n",
    "                    dict_landmark[file] = features\n",
    "                else:\n",
    "                    dict_landmark[file] = shape_np\n",
    "    return dict_landmark\n",
    "\n",
    "dict_land_ = {}\n",
    "dict_land_ = preprocessing(list_path_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db0a1e05-b1ac-4eed-9964-51cf04bdfea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_land_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498d189-3772-47ea-b611-b799e58a55d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4943eca-1205-409d-941b-70b448e5931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8003\n"
     ]
    }
   ],
   "source": [
    "###########temp~!!!!!!!!!!!!!!\n",
    "WALK = os.walk('/media/data1/mhkim/FakeAVCeleb_PREPROCESSED/FRAMES_PNG/C/TEST/REAL')\n",
    "\n",
    "list_path = []\n",
    "for (a,b,c) in WALK:\n",
    "    for _c in c:\n",
    "        if '.png' in _c:\n",
    "            list_path.append(os.path.join(a,_c))\n",
    "list_path.sort()\n",
    "\n",
    "print(len(list_path))\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    coords = (p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2\n",
    "    return [int(x) for x in coords]\n",
    "\n",
    "def preprocessing(list_path, find_main_point = False):\n",
    "    dict_landmark = {}\n",
    "    img_list = list_path\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    for file in img_list:\n",
    "        img = cv2.imread(file) #img must be cropped into face\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        if len(rects) > 0:\n",
    "            for rect in rects:\n",
    "                if find_main_point:\n",
    "                    x = rect.left()\n",
    "                    y = rect.top()\n",
    "                    w = rect.right()\n",
    "                    h = rect.bottom()\n",
    "                    img = img[y:h, x:w]\n",
    "\n",
    "                shape = predictor(img, rect)\n",
    "                shape_np = face_utils.shape_to_np(shape).tolist()\n",
    "                if find_main_point:\n",
    "                    left_eye = midpoint(shape_np[36], shape_np[39])\n",
    "                    right_eye = midpoint(shape_np[42], shape_np[45])\n",
    "                    features = [left_eye, right_eye, shape_np[33], shape_np[48], shape_np[54]]\n",
    "                    dict_landmark[file] = features\n",
    "                else:\n",
    "                    dict_landmark[file] = shape_np\n",
    "    return dict_landmark\n",
    "\n",
    "dict_land = {}\n",
    "dict_land = preprocessing(list_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb88af-dbc1-4ac1-ac5d-b0e9b3119a7b",
   "metadata": {},
   "source": [
    "# SAVE DICT -> JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e627b943-7068-4b66-a9b0-bff930ebc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "savetitle = 'land_real_test'\n",
    "with open(f'{savetitle}.json','w', encoding='utf-8') as make_file:\n",
    "    json.dump(dict_land,make_file,indent='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a32ea-5f15-4468-a428-fdcedc57b2e6",
   "metadata": {},
   "source": [
    "### LOAD JSON (FOR CHECK THE DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb4dc591-249b-4b89-9a9d-2531bb818966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59901"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('land_fake_train.json', 'r') as f:\n",
    "    landmarks_record =  json.load(f)\n",
    "len(landmarks_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7ee5245-31d2-47fd-a16e-467194a3cfea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[199, 403],\n",
       " [197, 473],\n",
       " [196, 542],\n",
       " [202, 608],\n",
       " [225, 669],\n",
       " [263, 721],\n",
       " [314, 761],\n",
       " [370, 785],\n",
       " [425, 794],\n",
       " [473, 789],\n",
       " [516, 764],\n",
       " [553, 731],\n",
       " [585, 692],\n",
       " [606, 648],\n",
       " [623, 601],\n",
       " [639, 554],\n",
       " [650, 504],\n",
       " [299, 403],\n",
       " [340, 381],\n",
       " [389, 374],\n",
       " [439, 382],\n",
       " [484, 397],\n",
       " [546, 405],\n",
       " [582, 397],\n",
       " [618, 402],\n",
       " [649, 417],\n",
       " [661, 444],\n",
       " [501, 456],\n",
       " [499, 495],\n",
       " [497, 535],\n",
       " [497, 576],\n",
       " [434, 597],\n",
       " [456, 605],\n",
       " [479, 614],\n",
       " [501, 611],\n",
       " [521, 606],\n",
       " [346, 442],\n",
       " [380, 437],\n",
       " [411, 439],\n",
       " [432, 461],\n",
       " [404, 462],\n",
       " [373, 458],\n",
       " [541, 474],\n",
       " [570, 459],\n",
       " [597, 462],\n",
       " [615, 476],\n",
       " [595, 485],\n",
       " [568, 482],\n",
       " [380, 670],\n",
       " [420, 661],\n",
       " [454, 658],\n",
       " [473, 666],\n",
       " [493, 662],\n",
       " [512, 671],\n",
       " [527, 683],\n",
       " [504, 698],\n",
       " [483, 705],\n",
       " [463, 707],\n",
       " [441, 703],\n",
       " [411, 692],\n",
       " [394, 672],\n",
       " [450, 679],\n",
       " [470, 684],\n",
       " [490, 682],\n",
       " [516, 684],\n",
       " [487, 679],\n",
       " [468, 681],\n",
       " [448, 677]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_record['/media/data1/mhkim/FakeAVCeleb_PREPROCESSED/FRAMES_PNG/C/TRAIN/FAKE/00001_0_1985/00018.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ecf5688-c119-4c8e-819a-dccd41014aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp.append(landmarks_record[list(landmarks_record)[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhmh",
   "language": "python",
   "name": "mhmh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
